{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa2547d",
   "metadata": {},
   "source": [
    "## DPR + Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ac6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import torch, faiss, numpy as np\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec08b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "ctx_model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(device)\n",
    "\n",
    "q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "q_model = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(device)\n",
    "\n",
    "cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPRVectorStore:\n",
    "    def __init__(self, ctx_model, q_model, ctx_tokenizer, q_tokenizer):\n",
    "        self.ctx_model = ctx_model\n",
    "        self.q_model = q_model\n",
    "        self.ctx_tokenizer = ctx_tokenizer\n",
    "        self.q_tokenizer = q_tokenizer\n",
    "        self.index = None\n",
    "        self.passages = []\n",
    "        self.embeddings = None\n",
    "\n",
    "    def build_index(self, passages):\n",
    "        self.passages = passages\n",
    "        inputs = self.ctx_tokenizer(passages, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            self.embeddings = self.ctx_model(**inputs.to(device)).pooler_output.cpu().numpy()\n",
    "        dim = self.embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(dim)\n",
    "        self.index.add(self.embeddings)\n",
    "\n",
    "    def query(self, question, top_k=5):\n",
    "        q_inputs = self.q_tokenizer(question, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            q_embed = self.q_model(**q_inputs).pooler_output.cpu().numpy()\n",
    "        D, I = self.index.search(q_embed, top_k)\n",
    "        results = [self.passages[i] for i in I[0]]\n",
    "        return results\n",
    "\n",
    "    def rerank(self, question, passages):\n",
    "        pairs = [(question, p) for p in passages]\n",
    "        scores = cross_encoder_model.predict(pairs)\n",
    "        ranked = [p for _, p in sorted(zip(scores, passages), reverse=True)]\n",
    "        return ranked, scores\n",
    "\n",
    "    def save_index(self, path=\"dpr_index.faiss\"):\n",
    "        faiss.write_index(self.index, path)\n",
    "\n",
    "    def load_index(self, path=\"dpr_index.faiss\"):\n",
    "        self.index = faiss.read_index(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849001ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 19\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"../data/Sales/Case Studies/Aura Health.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(\"Number of chunks:\", len(chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d11ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built with 19 chunks\n"
     ]
    }
   ],
   "source": [
    "retriever = DPRVectorStore(ctx_model, q_model, ctx_tokenizer, q_tokenizer)\n",
    "retriever.build_index([c.page_content for c in chunks])\n",
    "print(\"Index built with\", len(chunks), \"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55772e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPR Top-k Results:\n",
      "1. Emotion Detection Gap\n",
      "Therapists and wellness coaches needed better tools to create, \n",
      "publish, and monetize their content, but the platform lacked an \n",
      "intuitive, scalable interface to support growing creator needs.\n",
      "Creator Experience Limitations\n",
      "Aura’s expansion into workplaces required robust infrastructure to \n",
      "handle enterprise-scale usage, real-time personalization, and\n",
      "integration with collaboration tools all without sacriﬁcing\n",
      "performance or privacy.\n",
      "Scalability for Enterprise Use\n",
      "2. Impact\n",
      "Emotion AI delivered a 40% increase in content relevance, as users \n",
      "engaged more with mood-matched meditations, stories, and\n",
      "therapy sessions.\n",
      "Real-Time Personalization\n",
      "Upgraded UI/UX and personalized content journeys led to a 35% \n",
      "uplift in daily active users and a 25% increase in session duration \n",
      "across platforms.\n",
      "Boost in User Engagement\n",
      "The creator tools resulted in a 60% increase in audio content \n",
      "ploads and a 3x growth in active wellness coaches contributing \n",
      "to the platform.\n",
      "3. Developed and deployed AI models that detect emotional \n",
      "cues from user interactions in Slack, Zoom, and the\n",
      "mobile/web app, enabling dynamic content recommenda-\n",
      "tions tailored to users’ real-time mental states.\n",
      "Emotion Intelligence Integration\n",
      "Implemented a new design framework with consistent UI \n",
      "components across web and mobile, improving usability, \n",
      "accessibility, and responsiveness across all user journeys.\n",
      "Design System Modernization\n",
      "Refactored the platform’s front-end and back-end layers\n",
      "4. one that provides healing anytime, anywhere. At the heart of this vision \n",
      "is Aura’s Emotion AI, a powerful capability that reads user emotions \n",
      "from their interactions across Slack, Zoom, and other tools, then\n",
      "recommends tailored content such as guided meditations, sleep\n",
      "stories, or cognitive therapy sessions.Through its extensive wellness \n",
      "marketplace, the platform empowers certiﬁed coaches and therapists \n",
      "to publish audio content, build supportive communities, and offer\n",
      "5. coaching—directly enriching Aura’s marketplace and\n",
      "increasing platform engagement.\n",
      "Creator Enablement Tools\n",
      "Designed scalable infrastructure for the growing wellness \n",
      "marketplace, supporting new categories, regional content \n",
      "ﬁlters, and performance analytics for creators.\n",
      "Marketplace Ecosystem Expansion\n",
      "Ensured HIPAA and GDPR alignment through secure data \n",
      "handling, consent-based emotion tracking, and\n",
      "anonymized insights protecting user privacy while enabling \n",
      "meaningful personalization.\n",
      "\n",
      "Cross-Encoder Reranked Results:\n",
      "1. Developed and deployed AI models that detect emotional \n",
      "cues from user interactions in Slack, Zoom, and the\n",
      "mobile/web app, enabling dynamic content recommenda-\n",
      "tions tailored to users’ real-time mental states.\n",
      "Emotion Intelligence Integration\n",
      "Implemented a new design framework with consistent UI \n",
      "components across web and mobile, improving usability, \n",
      "accessibility, and responsiveness across all user journeys.\n",
      "Design System Modernization\n",
      "Refactored the platform’s front-end and back-end layers (score: -3.5556)\n",
      "2. one that provides healing anytime, anywhere. At the heart of this vision \n",
      "is Aura’s Emotion AI, a powerful capability that reads user emotions \n",
      "from their interactions across Slack, Zoom, and other tools, then\n",
      "recommends tailored content such as guided meditations, sleep\n",
      "stories, or cognitive therapy sessions.Through its extensive wellness \n",
      "marketplace, the platform empowers certiﬁed coaches and therapists \n",
      "to publish audio content, build supportive communities, and offer (score: -5.6256)\n",
      "3. Emotion Detection Gap\n",
      "Therapists and wellness coaches needed better tools to create, \n",
      "publish, and monetize their content, but the platform lacked an \n",
      "intuitive, scalable interface to support growing creator needs.\n",
      "Creator Experience Limitations\n",
      "Aura’s expansion into workplaces required robust infrastructure to \n",
      "handle enterprise-scale usage, real-time personalization, and\n",
      "integration with collaboration tools all without sacriﬁcing\n",
      "performance or privacy.\n",
      "Scalability for Enterprise Use (score: 7.5982)\n",
      "4. Impact\n",
      "Emotion AI delivered a 40% increase in content relevance, as users \n",
      "engaged more with mood-matched meditations, stories, and\n",
      "therapy sessions.\n",
      "Real-Time Personalization\n",
      "Upgraded UI/UX and personalized content journeys led to a 35% \n",
      "uplift in daily active users and a 25% increase in session duration \n",
      "across platforms.\n",
      "Boost in User Engagement\n",
      "The creator tools resulted in a 60% increase in audio content \n",
      "ploads and a 3x growth in active wellness coaches contributing \n",
      "to the platform. (score: -3.5158)\n",
      "5. coaching—directly enriching Aura’s marketplace and\n",
      "increasing platform engagement.\n",
      "Creator Enablement Tools\n",
      "Designed scalable infrastructure for the growing wellness \n",
      "marketplace, supporting new categories, regional content \n",
      "ﬁlters, and performance analytics for creators.\n",
      "Marketplace Ecosystem Expansion\n",
      "Ensured HIPAA and GDPR alignment through secure data \n",
      "handling, consent-based emotion tracking, and\n",
      "anonymized insights protecting user privacy while enabling \n",
      "meaningful personalization. (score: -6.9207)\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Emotion Intelligence Integration?\"\n",
    "\n",
    "dpr_results = retriever.query(query, top_k=5)\n",
    "reranked, scores = retriever.rerank(query, dpr_results)\n",
    "\n",
    "print(\"DPR Top-k Results:\")\n",
    "for i, p in enumerate(dpr_results, 1):\n",
    "    print(f\"{i}. {p}\")\n",
    "\n",
    "print(\"\\nCross-Encoder Reranked Results:\")\n",
    "for i, (p, s) in enumerate(zip(reranked, scores), 1):\n",
    "    print(f\"{i}. {p} (score: {s:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9e27137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def retrieve_documents(query: str):\n",
    "    \"\"\"Retrieve relevant documents.\"\"\"\n",
    "    dpr_results = retriever.query(query, top_k=3)\n",
    "    reranked, scores = retriever.rerank(query, dpr_results)\n",
    "\n",
    "    return reranked\n",
    "\n",
    "tools = [retrieve_documents]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL_SYSTEM_PROMPT = \"\"\"\n",
    "You are a professional email assistant for our company's sales team. Your role is to respond to customer inquiries using ONLY information from our knowledge base.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. You MUST respond in proper business email format with subject line, salutation, body, and signature\n",
    "2. If the customer's question can be answered using the provided context, write a helpful, professional email response\n",
    "3. If the information is NOT in the knowledge base (context shows \"NO_RELEVANT_INFORMATION_FOUND\"), respond with a polite email explaining this\n",
    "4. Never invent information or use external knowledge\n",
    "5. Maintain a professional, helpful tone in all communications\n",
    "6. Format your response as a ready-to-send email\n",
    "7. Always start the subject with \"Re: \" followed by the original subject or an appropriate title\n",
    "\n",
    "EMAIL FORMAT:\n",
    "Subject: Re: [Original Subject or Appropriate Title]\n",
    "\n",
    "Dear [Customer Name],\n",
    "\n",
    "[Professional email body acknowledging their query and providing information or explaining limitations]\n",
    "\n",
    "[Clear next steps or contact information if needed]\n",
    "\n",
    "Best regards,\n",
    "[Sale Team]\n",
    "[Strategisthub]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.graph import START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind_tools(tools)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                        content=EMAIL_SYSTEM_PROMPT\n",
    "                    )\n",
    "        ]\n",
    "        + state[\"messages\"]\n",
    "        )\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# 7. Build graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# app = workflow.compile()\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5226cf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: Inquiry About Emotion Intelligence Integration\n",
      "\n",
      "Dear [Customer Name],\n",
      "\n",
      "Thank you for your inquiry regarding Emotion Intelligence Integration. \n",
      "\n",
      "Emotion Intelligence Integration involves the development and deployment of AI models that detect emotional cues from user interactions across various platforms such as Slack, Zoom, and mobile/web applications. This technology enables dynamic content recommendations tailored to users' real-time mental states, enhancing user engagement and content relevance.\n",
      "\n",
      "For instance, the implementation of this integration has led to a 40% increase in content relevance, as users engage more with mood-matched meditations, stories, and therapy sessions. Additionally, it has contributed to a significant boost in user engagement metrics.\n",
      "\n",
      "If you have any further questions or need more detailed information, please feel free to reach out.\n",
      "\n",
      "Best regards,  \n",
      "Sales Team  \n",
      "Strategisthub\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "response = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    config\n",
    ")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2f41658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: Inquiry About Aura Health\n",
      "\n",
      "Dear [Customer Name],\n",
      "\n",
      "Thank you for your inquiry about Aura Health.\n",
      "\n",
      "Aura Health is a globally recognized leader in mental wellness, trusted by over 8 million users. It has been honored with several awards, including Apple’s Best of Apps and the Very Well Mind Online Therapy and Wellness Award. Aura provides a category-defining platform in digital wellness, combining the expertise of the world’s best coaches and therapists to deliver a deeply personalized self-care journey for each user.\n",
      "\n",
      "The platform's vision is to create a global digital ecosystem for mental health, offering healing anytime and anywhere. A key feature of Aura is its Emotion AI, which reads user emotions from their interactions across various tools and recommends tailored content such as guided meditations, sleep stories, and cognitive therapy sessions.\n",
      "\n",
      "If you have any further questions or need additional information, please feel free to reach out.\n",
      "\n",
      "Best regards,  \n",
      "Sales Team  \n",
      "Strategisthub\n"
     ]
    }
   ],
   "source": [
    "query = \"What is aura health?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "response = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    config\n",
    ")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53da031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e69954e4",
   "metadata": {},
   "source": [
    "# Testing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630e5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from supabase_auth import datetime\n",
    "from langchain_core.documents import Document\n",
    "from pathlib import Path\n",
    "import json, shutil\n",
    "import uvicorn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from app.data_loader import read_uploaded_file\n",
    "\n",
    "from app.data_loader import read_uploaded_file\n",
    "from app.tools import create_retriever_tool\n",
    "from app.graph_builder import build_workflow\n",
    "import os\n",
    "# from app.vectorstore_weaviate import create_or_load_vectorstore, load_vectorstore\n",
    "from app.vectorstore_supabase import (\n",
    "    get_active_prompt,\n",
    ")\n",
    "\n",
    "\n",
    "# def handle_query(request):\n",
    "#     active_prompt_data = get_active_prompt()\n",
    "#     if not active_prompt_data or \"active_prompt\" not in active_prompt_data:\n",
    "#         # raise HTTPException(status_code=404, detail=\"No active prompt found.\")\n",
    "#         print(\"No active prompt found.\")\n",
    "#         return {\"response\": \"No active prompt found.\"}\n",
    "    \n",
    "#     system_prompt = active_prompt_data[\"active_prompt\"][\"prompt\"]\n",
    "#     tools = create_retriever_tool()\n",
    "#     graph = build_workflow(tools, system_prompt)\n",
    "#     config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "#     response = graph.invoke({\"messages\": request.query}, config=config)\n",
    "#     return {\"response\": response[\"messages\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd229e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def handle_query(request):\n",
    "#     active_prompt_data = get_active_prompt()\n",
    "#     if not active_prompt_data or \"active_prompt\" not in active_prompt_data:\n",
    "#         print(\"No active prompt found.\")\n",
    "#         return {\"response\": \"No active prompt found.\", \"sources\": []}\n",
    "    \n",
    "#     system_prompt = active_prompt_data[\"active_prompt\"][\"prompt\"]\n",
    "#     tools = create_retriever_tool()\n",
    "#     graph = build_workflow(tools, system_prompt)\n",
    "#     config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "#     result = graph.invoke({\"messages\": request.query}, config=config)\n",
    "\n",
    "#     messages = result[\"messages\"]\n",
    "\n",
    "#     # ----- Extract final response -----\n",
    "#     final_ai_msg = None\n",
    "#     for msg in messages:\n",
    "#         if msg.__class__.__name__ == \"AIMessage\" and msg.content:\n",
    "#             final_ai_msg = msg.content\n",
    "\n",
    "#     # ----- Extract sources from ToolMessage -----\n",
    "#     sources = []\n",
    "#     for msg in messages:\n",
    "#         if msg.__class__.__name__ == \"ToolMessage\":\n",
    "#             if hasattr(msg, \"artifact\") and msg.artifact:\n",
    "#                 for item in msg.artifact:\n",
    "#                     sources.append({\n",
    "#                         \"source\": item[\"metadata\"].get(\"source\"),\n",
    "#                         \"content\": item[\"page_content\"],\n",
    "#                         \"rerank_score\": item.get(\"rerank_score\")\n",
    "#                     })\n",
    "\n",
    "#     return {\n",
    "#         \"response\": final_ai_msg,\n",
    "#         \"sources\": sources\n",
    "#     }\n",
    "\n",
    "\n",
    "def handle_query(request):\n",
    "    active_prompt_data = get_active_prompt()\n",
    "    if not active_prompt_data or \"active_prompt\" not in active_prompt_data:\n",
    "        print(\"No active prompt found.\")\n",
    "        return {\"response\": \"No active prompt found.\"}\n",
    "    \n",
    "    system_prompt = active_prompt_data[\"active_prompt\"][\"prompt\"]\n",
    "    tools = create_retriever_tool()\n",
    "    graph = build_workflow(tools, system_prompt)\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "    result = graph.invoke({\"messages\": request.query}, config=config)\n",
    "    messages = result[\"messages\"]\n",
    "\n",
    "    # ----- Extract final AI response -----\n",
    "    final_ai_msg = \"\"\n",
    "    for msg in messages:\n",
    "        if msg.__class__.__name__ == \"AIMessage\" and msg.content:\n",
    "            final_ai_msg = msg.content\n",
    "\n",
    "    # ----- Extract sources from ToolMessage -----\n",
    "    source_names = []\n",
    "    for msg in messages:\n",
    "        if msg.__class__.__name__ == \"ToolMessage\" and hasattr(msg, \"artifact\"):\n",
    "            for item in msg.artifact:\n",
    "                src = item[\"metadata\"].get(\"source\")\n",
    "                if src and src not in source_names:\n",
    "                    source_names.append(src)\n",
    "\n",
    "    # ----- Append sources at the end of response -----\n",
    "    if source_names:\n",
    "        final_ai_msg += \"\\n\\nSources:\\n\" + \"\\n\".join(\n",
    "            f\"- {src}\" for src in source_names\n",
    "        )\n",
    "\n",
    "    return {\"response\": final_ai_msg}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78606012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in the tool...\n",
      "Got some data...\n",
      "Re-Ranking the results...\n",
      "{'response': 'Aura Health is a leading global platform in the mental wellness industry, trusted by over 8 million users. It has been recognized as a \"BEST OF APPS\" winner by Apple and received the Verywell Mind Online Therapy and Wellness Award in 2023. The platform connects users with a variety of coaches and therapists and offers a personalized library of wellness content, which includes meditations, stories, and cognitive behavioral therapy (CBT).\\n\\nSources:\\n- StrategistHub-Portfolio.pdf\\n- Company Profile.pdf\\n- PitchDeck.pdf'}\n"
     ]
    }
   ],
   "source": [
    "response = handle_query(type('obj', (object,), {'query': 'What is aura health?'}))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf4962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in the tool...\n",
      "Got some data...\n",
      "Re-Ranking the results...\n",
      "{'response': 'StrategistHub offers a range of major services focused on helping businesses build scalable and high-performance digital solutions. Here are the key services:\\n\\n1. **Custom Software Development**: Tailored software solutions designed to meet specific business needs.\\n\\n2. **AI-Driven Solutions**: Integration of artificial intelligence to enhance operations and user experiences.\\n\\n3. **Advanced System Architecture**: Expertise in creating robust and efficient system architectures.\\n\\n4. **Engineering Excellence**: Providing highly skilled software engineers to drive digital transformation.\\n\\n5. **Consultation and Strategy**: Collaborating with clients to ensure solutions align with business goals and deliver measurable impact.\\n\\n6. **Support for Startups and Enterprises**: Services catered to both tech startups and large enterprises, addressing complex challenges across various industries.\\n\\nStrategistHub positions itself as a trusted technology partner with over a decade of experience in software development and engineering services.\\n\\nSources:\\n- PitchDeck.pdf'}\n"
     ]
    }
   ],
   "source": [
    "response = handle_query(type('obj', (object,), {'query': 'What are the major services of Strategisthub?'}))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2fa632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CustomizeGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
